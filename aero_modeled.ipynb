{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BQ Load "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_id = \"aero_staging\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigQuery error in mk operation: Dataset 'probable-pager-266720:aero_staging'\n",
      "already exists.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=US mk --dataset {dataset_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting on bqjob_r1268eaf45a535339_0000017194bda074_1 ... (2s) Current status: DONE   \n"
     ]
    }
   ],
   "source": [
    "!bq --location=US load --autodetect --skip_leading_rows=1 \\\n",
    "--source_format=CSV {dataset_id}.birds_eye \\\n",
    "'gs://areo-data/AERO-BirdsEye-Data.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeled Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery \n",
    "\n",
    "create table aero_modeled.birds_eye as\n",
    "select nct_number, sponsor, title, start_year, start_month, phase, condition\n",
    "from aero_staging.birds_eye"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>27496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  27496\n",
       "1  13748"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "select count(*) as count from aero_modeled.birds_eye \n",
    "union all \n",
    "select count(distinct nct_number) as counter from aero_modeled.birds_eye "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_number</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NCT00142558</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NCT00798369</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NCT00819585</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NCT00927810</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCT01029652</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NCT01080131</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NCT02187029</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NCT00141401</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NCT00150423</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NCT00156078</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    nct_number  count\n",
       "0  NCT00142558      2\n",
       "1  NCT00798369      2\n",
       "2  NCT00819585      2\n",
       "3  NCT00927810      2\n",
       "4  NCT01029652      2\n",
       "5  NCT01080131      2\n",
       "6  NCT02187029      2\n",
       "7  NCT00141401      2\n",
       "8  NCT00150423      2\n",
       "9  NCT00156078      2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "select nct_number, count(nct_number) as count\n",
    "from aero_modeled.birds_eye \n",
    "group by nct_number\n",
    "having count(nct_number) > 1 limit 10;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'aero_modeled'\n",
      " projectId: 'probable-pager-266720'\n",
      " tableId: 'birds_eye'> referenced by query SELECT nct_number, sponsor, title, start_year, start_month, phase, condition FROM aero_modeled.birds_eye limit 10\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset probable-pager-266720:temp_dataset_de07dc1dffe248ceaf1959f57788c47c does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table probable-pager-266720.aero_modeled.birds_eye_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'nct_number'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'sponsor'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'phase'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'condition'\n",
      " type: 'STRING'>]>. Result: <Table\n",
      " creationTime: 1587864611813\n",
      " etag: 'RWun0wv4JIOEQNjSxk8NyQ=='\n",
      " id: 'probable-pager-266720:aero_modeled.birds_eye_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1587864611880\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'nct_number'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'sponsor'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'title'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_year'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'start_month'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'phase'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'condition'\n",
      " type: 'STRING'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/probable-pager-266720/datasets/aero_modeled/tables/birds_eye_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'aero_modeled'\n",
      " projectId: 'probable-pager-266720'\n",
      " tableId: 'birds_eye_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n"
     ]
    }
   ],
   "source": [
    "%run birds_eye_beam.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpf8hbx7k7', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpf8hbx7k7', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://ncorona-lyme-ncl/staging/birds-eye-df.1587864892.810286/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-04-26T01:34:58.498183Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-04-25_18_34_57-5077923610623220954'\n",
      " location: 'us-central1'\n",
      " name: 'birds-eye-df'\n",
      " projectId: 'probable-pager-266720'\n",
      " stageStates: []\n",
      " startTime: '2020-04-26T01:34:58.498183Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-04-25_18_34_57-5077923610623220954]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-04-25_18_34_57-5077923610623220954?project=probable-pager-266720\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-25_18_34_57-5077923610623220954 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:34:57.467Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-04-25_18_34_57-5077923610623220954.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:34:57.467Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-04-25_18_34_57-5077923610623220954. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:00.729Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:01.450Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.043Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.069Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write results/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.089Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Grouped table records: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.115Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Write records input/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.142Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.172Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.281Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.534Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.553Z: JOB_MESSAGE_DETAILED: Fusing consumer Extract table records into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.581Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.608Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/WriteBundles/WriteBundles into Dedup table records\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.636Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Dedup table records\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.665Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/Pair into Write records input/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.696Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/WindowInto(WindowIntoFn) into Write records input/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.720Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/GroupByKey/Reify into Write records input/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.744Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/GroupByKey/Write into Write records input/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.773Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/GroupByKey/GroupByWindow into Write records input/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.807Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/Extract into Write records input/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.830Z: JOB_MESSAGE_DETAILED: Fusing consumer Grouped table records/Reify into Extract table records\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.857Z: JOB_MESSAGE_DETAILED: Fusing consumer Grouped table records/Write into Grouped table records/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.886Z: JOB_MESSAGE_DETAILED: Fusing consumer Grouped table records/GroupByWindow into Grouped table records/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.918Z: JOB_MESSAGE_DETAILED: Fusing consumer Dedup table records into Grouped table records/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.948Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/Pair into Write results/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:02.979Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/WindowInto(WindowIntoFn) into Write results/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/GroupByKey/Reify into Write results/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.025Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/GroupByKey/Write into Write results/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.056Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/GroupByKey/GroupByWindow into Write results/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.079Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/Extract into Write results/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.100Z: JOB_MESSAGE_DETAILED: Fusing consumer Write records input/Write/WriteImpl/InitializeWrite into Write records input/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.124Z: JOB_MESSAGE_DETAILED: Fusing consumer Write results/Write/WriteImpl/InitializeWrite into Write results/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.147Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.176Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.201Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.227Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.405Z: JOB_MESSAGE_DEBUG: Executing wait step start39\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.470Z: JOB_MESSAGE_BASIC: Executing operation Write results/Write/WriteImpl/DoOnce/Read+Write results/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.495Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/DoOnce/Read+Write records input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.506Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.521Z: JOB_MESSAGE_BASIC: Executing operation Grouped table records/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.525Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.549Z: JOB_MESSAGE_BASIC: Executing operation Write results/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.565Z: JOB_MESSAGE_BASIC: Finished operation Grouped table records/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.569Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.596Z: JOB_MESSAGE_BASIC: Finished operation Write results/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.613Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.626Z: JOB_MESSAGE_DEBUG: Value \"Grouped table records/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.654Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:03.676Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-04-25_18_34_57-5077923610623220954 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:35:33.783Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running stage(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:37:26.811Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:37:26.838Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.045Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/DoOnce/Read+Write records input/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.109Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.138Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.188Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.212Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.228Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.233Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.248Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.276Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.286Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.313Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.335Z: JOB_MESSAGE_DEBUG: Value \"Write records input/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.373Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Extract table records+Write records input/Write/WriteImpl/WriteBundles/WriteBundles+Write records input/Write/WriteImpl/Pair+Write records input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write records input/Write/WriteImpl/GroupByKey/Reify+Write records input/Write/WriteImpl/GroupByKey/Write+Grouped table records/Reify+Grouped table records/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:06.483Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_10862498572479259336\". You can check its status with the bq tool: \"bq show -j --project_id=probable-pager-266720 dataflow_job_10862498572479259336\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.659Z: JOB_MESSAGE_BASIC: Finished operation Write results/Write/WriteImpl/DoOnce/Read+Write results/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.710Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.736Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.777Z: JOB_MESSAGE_BASIC: Executing operation Write results/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.798Z: JOB_MESSAGE_BASIC: Executing operation Write results/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.817Z: JOB_MESSAGE_BASIC: Finished operation Write results/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.825Z: JOB_MESSAGE_BASIC: Executing operation Write results/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.840Z: JOB_MESSAGE_BASIC: Finished operation Write results/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.867Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.870Z: JOB_MESSAGE_BASIC: Finished operation Write results/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.896Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:38:09.915Z: JOB_MESSAGE_DEBUG: Value \"Write results/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:14.559Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_10862498572479259336\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:15.339Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_17851514997672594232\" started. You can check its status with the bq tool: \"bq show -j --project_id=probable-pager-266720 dataflow_job_17851514997672594232\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:45.731Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_17851514997672594232\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:45.765Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_17851514997672594232\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.007Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Extract table records+Write records input/Write/WriteImpl/WriteBundles/WriteBundles+Write records input/Write/WriteImpl/Pair+Write records input/Write/WriteImpl/WindowInto(WindowIntoFn)+Write records input/Write/WriteImpl/GroupByKey/Reify+Write records input/Write/WriteImpl/GroupByKey/Write+Grouped table records/Reify+Grouped table records/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.064Z: JOB_MESSAGE_BASIC: Executing operation Grouped table records/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.087Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.118Z: JOB_MESSAGE_BASIC: Finished operation Grouped table records/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.139Z: JOB_MESSAGE_BASIC: Finished operation Write records input/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.174Z: JOB_MESSAGE_BASIC: Executing operation Grouped table records/Read+Grouped table records/GroupByWindow+Dedup table records+Write results/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Write results/Write/WriteImpl/Pair+Write results/Write/WriteImpl/WindowInto(WindowIntoFn)+Write results/Write/WriteImpl/GroupByKey/Reify+Write results/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-04-26T01:39:58.204Z: JOB_MESSAGE_BASIC: Executing operation Write records input/Write/WriteImpl/GroupByKey/Read+Write records input/Write/WriteImpl/GroupByKey/GroupByWindow+Write records input/Write/WriteImpl/Extract\n"
     ]
    }
   ],
   "source": [
    "%run birds_eye_beam_dataflow.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Primary Key & Duplicate Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count\n",
       "0  13748\n",
       "1  13748"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "select count(*) as count from aero_modeled.birds_eye_Beam_DF\n",
    "union all \n",
    "select count(distinct nct_number) as count from aero_modeled.birds_eye_Beam_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nct_number</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [nct_number, count]\n",
       "Index: []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "\n",
    "select nct_number, count(nct_number) as count\n",
    "from aero_modeled.birds_eye_Beam_DF\n",
    "group by nct_number\n",
    "having count(nct_number) > 1 limit 10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
